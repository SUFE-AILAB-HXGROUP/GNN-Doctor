# GNN-Doctor
Privacy Risk Assessment of Graph Neural Networks

# GCL-Privacy-Risk Project
## Systematically Evaluation of Privacy Leakage of Graph Contrastive Learning Models
**1. Inference Attacks against GCL Models:**
* Attribute / Property Inference Attack
* Membership Inference Attack
* Private link Inference Attack / Reconstruction Attack
* Subgraph Inference Attack (to be determined)

**2. References**
* (2022 USENIX) Inference Attacks Against Graph Neural Networks
* (2021 CCS) Quantifying and Mitigating Privacy Risks in Contrastive Learning
* (2020 MobiQuitous) Quantifying Privacy Leakage in Graph Embedding
* (2022 USENIX) ML-DOCTOR: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models

**3. Acknowledgement**
* Reference of source code of ***GraphCL***: https://github.com/Shen-Lab/GraphCL
* Reference of source code of ***GCA***: https://github.com/CRIPAC-DIG/GCA
* ***PyGCL***: Graph Contrastive Learning Library for PyTorch: https://github.com/GraphCL/PyGCL
